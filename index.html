<!DOCTYPE html>

<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta content="IE=5.0000" http-equiv="X-UA-Compatible">
  <meta name="description" content="Zhenyu Li's home page"> 
  
  <link href="./files/wfdoc.css" rel="stylesheet" type="text/css"> 
  <title>Zhenyu Li's Homepage</title> 
  <meta name="GENERATOR" content="MSHTML 11.00.10570.1001">
</head>


<body> 
  <div id="layout-content" style="margin-top: 25px;">
  <table>
    <tbody>
    <tr>
      <td width="670">
        <div id="toptitle">
        <h1>Zhenyu Li &nbsp; 李震宇</h1></div>
        <h3>Postgraduate</h3>
        <br>Advanced Imaging and Intelligent Analysis Laboratory
        <br>Computing Faculty,
        <br>Harbin Institute of Technology
        <br>Harbin, China
        <br>
        <br> Email:  
        <a href="zhenyuli17@hit.edu.cn"> zhenyuli17@hit.edu.cn</a>; 
        <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="vgumypxt@gmail.com">     vgumypxt@gmail.com</a>; 
        <br> Github: 
        <a href="https://github.com/zhyever">https://github.com/zhyever</a> 
        <br><br></p>
      </td>
      <td>
        <img width="180" src="./files/zhenyuli.jpg" border="0">
      </td>
    </tr>
    <tr></tr></tbody>
  </table>
  <div id="layout-content" style="margin-top: 25px;">


  <h2>Biography</h2>

  <p> I am a postgraduate student working with Prof. Junjun Jiang at Harbin Institute of Technology (HIT).
    I got the B.S. degree in computer science at HIT in 2021. </p>
  <p> My research interests include 3D reconstruction, scene perception, and understanding.</p>


<h2>Experience</h2>
<ul>

  <li>
    Jan.2022 - July.2022, <i>Perception Research Intern</i>, <b>SenseTime</b>
  </li>
  <li>
    Mar.2021 - Sep.2021, <i>Perception Research Intern</i>, <b>SenseTime</b>
  </li>

</ul>

<h2>Awards</h2>
<ul>
  <li>
    <b>6<sup>th</sup></b> place at Mobile AI 2021 Challenge, Monocular Depth Estimation! (<b>CVPR 2021</b> Workshop)
  </li>
</ul>

<h2>Publications</h2>

<table class="pub_table">
  <tbody>
  
  <tr>
    <td class="pub_td1"><img src="./files/stmono3d.png" class="papericon"></td>
    <td class="pub_td2"><u>Zhenyu Li</u>, Zehui Chen, Ang Li, Liangji Fang, Qinhong Jiang, Xianming Liu, Junjun Jiang
      <br><b>Unsupervised Domain Adaptation for Monocular 3D Object Detection via Self-Training</b>
      <br>ECCV, 2022
      <br>
      [<a href="https://arxiv.org/abs/2204.11590">PDF</a>]
      <!-- [<a href="https://github.com/zhyever/DAMono3D">Code</a>] -->
    </td>
  </tr>

  <tr>
    <td class="pub_td1"><img src="./files/simipu.png" class="papericon"></td>
    <td class="pub_td2"><u>Zhenyu Li</u>, Zehui Chen, Ang Li, Liangji Fang, Qinhong Jiang, Xianming Liu, Junjun Jiang, Bolei Zhou, Hang Zhao
      <br><b>SimIPU: Simple 2D Image and 3D Point Cloud Unsupervised Pre-Training for Spatial-Aware Visual Representations</b>
      <br>AAAI, 2022
      <br>
      [<a href="https://arxiv.org/abs/2112.04680">PDF</a>][<a href="https://github.com/zhyever/SimIPU">Code</a>]
    </td>
  </tr>

  <tr>
    <td class="pub_td1"><img src="./files/dgmono3d.png" class="papericon"></td>
    <td class="pub_td2"><u>Zhenyu Li</u>, Zehui Chen, Ang Li, Liangji Fang, Qinhong Jiang, Xianming Liu, Junjun Jiang
      <br><b>Towards Model Generalization for Monocular 3D Object Detection</b>
      <br>Arxiv
      <br>
      [<a href="https://arxiv.org/abs/2205.11664">PDF</a>]
      <!-- [<a href="https://github.com/zhyever/Monocular-Depth-Estimation-Toolbox">Code</a>] -->
    </td>
  </tr>

  <tr>
    <td class="pub_td1"><img src="./files/binsformer.png" class="papericon"></td>
    <td class="pub_td2"><u>Zhenyu Li</u>, Xuyang Wang, Xianming Liu, Junjun Jiang
      <br><b>BinsFormer: Revisiting Adaptive Bins for Monocular Depth Estimation</b>
      <br><font color="red">Ranked <b>1<sup>st</sup></b> on KITTI depth estimation benchmark (Feb, 2022).</font>
      <br>Arxiv
      <br>
      [<a href="https://arxiv.org/abs/2204.00987">PDF</a>]
      <!-- [<a href="https://github.com/zhyever/Monocular-Depth-Estimation-Toolbox">Code</a>] -->
    </td>
  </tr>

  <tr>
    <td class="pub_td1"><img src="./files/depthformer.png" class="papericon"></td>
    <td class="pub_td2"><u>Zhenyu Li</u>, Zehui Chen, Xianming Liu, Junjun Jiang
      <br><b>DepthFormer: Exploiting Long-Range Correlation and Local Information for Accurate Monocular Depth Estimation</b>
      <br><font color="red">Ranked <b>1<sup>st</sup></b> on KITTI depth estimation benchmark (Nov, 2021).</font>
      <br>Arxiv
      <br>
      [<a href="https://arxiv.org/abs/2203.14211">PDF</a>]
      [<a href="https://github.com/zhyever/Monocular-Depth-Estimation-Toolbox">Code</a>]
    </td>
  </tr>

  <tr>
    <td class="pub_td1"><img src="./files/graphdetr3d.png" class="papericon"></td>
    <td class="pub_td2">Zehui Chen, <u>Zhenyu Li</u>, Shiquan Zhang, Liangji Fang, Qinhong Jiang, Feng Zhao
      <br><b>Graph-DETR3D: Rethinking Overlapping Regions for Multi-View 3D Object Detection</b>
      <br>ACM MM, 2022<br>
      [<a href="https://arxiv.org/abs/2201.06493">PDF</a>]
    </td>
  </tr>

  <tr>
    <td class="pub_td1"><img src="./files/autoalignv2.png" class="papericon"></td>
    <td class="pub_td2">Zehui Chen, <u>Zhenyu Li</u>, Shiquan Zhang, Liangji Fang, Qinhong Jiang, Feng Zhao
      <br><b>AutoAlignV2: Deformable Feature Aggregation for Dynamic Multi-Modal 3D Object Detection</b>
      <br>ECCV, 2022<br>
      [<a href="https://github.com/zehuichen123/AutoAlignV2">Code</a>]
    </td>
  </tr>

  <tr>
    <td class="pub_td1"><img src="./files/autoalign.png" class="papericon"></td>
    <td class="pub_td2">Zehui Chen, <u>Zhenyu Li</u>, Shiquan Zhang, Liangji Fang, Qinhong Jiang, Feng Zhao, Bolei Zhou, Hang Zhao
      <br><b>AutoAlign: Pixel-Instance Feature Aggregation for Multi-Modal 3D Object Detection</b>
      <br>IJCAI, 2022
      <br>
      [<a href="https://arxiv.org/abs/2201.06493">PDF</a>]
    </td>
  </tr>

  

  </tbody>
</table>

    
<br>





</div></div></body></html>
